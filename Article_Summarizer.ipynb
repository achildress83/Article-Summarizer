{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Article Summarizer**"
      ],
      "metadata": {
        "id": "3damLdZD4Xrm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "cellView": "form",
        "id": "-Ybrk5TlJqLv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56f0e274-2f4d-427d-a06a-837c4524a47d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#@title Install Libraries\n",
        "!pip install python-dotenv --quiet\n",
        "!pip install beautifulsoup4 --quiet\n",
        "!pip install langchain --quiet\n",
        "!pip install openai --quiet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up Google Colab and Environment Variables\n"
      ],
      "metadata": {
        "id": "NbDhimmV3urx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup Code\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv, dotenv_values\n",
        "\n",
        "# mount google drive to access project path\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "project_path = '/content/gdrive/MyDrive/Colab Notebooks/'\n",
        "\n",
        "# get dotenv file from project folder\n",
        "dotenv_file = project_path + '.env'\n",
        "\n",
        "print(f\"Checks that API keys are available\\nEnvironment Vars loaded: {load_dotenv(dotenv_file)}\\n\")\n",
        "\n",
        "# assign all API keys to variables and add variables to 'keys' list\n",
        "OPEN_API_KEY = os.getenv('OPENAI_API_KEY')\n",
        "keys = [OPEN_API_KEY]\n",
        "\n",
        "def keys_available(keys):\n",
        "  \"\"\"checks that keys successfully imported\"\"\"\n",
        "  return [type(key) for key in keys]\n",
        "\n",
        "# Should be string. If NoneType in list, API import failed for that particular key.\n",
        "print(f\"All API keys should be strings: {keys_available(keys)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KErrchXTT5sH",
        "outputId": "eeb19f42-b4b7-4526-f122-d26d3de4c924",
        "cellView": "form"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "Checks that API keys are available\n",
            "Environment Vars loaded: True\n",
            "\n",
            "All API keys should be strings: [<class 'str'>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scrape Articles from Source"
      ],
      "metadata": {
        "id": "DkSfhUwF9GiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Scraper Code\n",
        "\n",
        "import requests\n",
        "import time as t\n",
        "from bs4 import BeautifulSoup\n",
        "from enum import Enum\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "url = \"https://venturebeat.com/category/ai/\"\n",
        "\n",
        "class Date(Enum):\n",
        "  today = 'today'\n",
        "  yesterday = 'yesterday'\n",
        "  more = 'more'\n",
        "\n",
        "  def __str__(self):\n",
        "      return self.value\n",
        "\n",
        "def get_text(detail_url):\n",
        "  info = BeautifulSoup(requests.get(detail_url).text, 'lxml')\n",
        "  return '\\n'.join([p.text.strip() for p in info.select_one('div.article-content').findChildren('p', recursive=False)])\n",
        "\n",
        "\n",
        "def scrape(date = Date.today):\n",
        "  rr = requests.get( url )\n",
        "\n",
        "  soup = BeautifulSoup(rr.text, \"lxml\")\n",
        "\n",
        "\n",
        "  articles= soup.find_all('article', class_='ArticleListing')\n",
        "\n",
        "  print('#### input ###')\n",
        "  print('date: ', date)\n",
        "  print('#### === ### \\n')\n",
        "  data = []\n",
        "  for article in articles:\n",
        "    t.sleep(5)\n",
        "    if not article.time:\n",
        "      continue\n",
        "    time = article.time.text.strip()\n",
        "    item = {\n",
        "        'title': article.h2.text.strip(),\n",
        "        'url': article.a['href'],\n",
        "        'time': time\n",
        "    }\n",
        "    time_obj = datetime.strptime(time, '%B %d, %Y %H:%M %p').date()\n",
        "    if date == Date.today:\n",
        "      if time_obj == datetime.today().date():\n",
        "        item['text'] = get_text(article.a['href'])\n",
        "        data.append(item)\n",
        "    elif date == Date.yesterday:\n",
        "      if time_obj == (datetime.today() - timedelta(days=1)).date():\n",
        "        item['text'] = get_text(article.a['href'])\n",
        "        data.append(item)\n",
        "    elif date == Date.more:\n",
        "      item['text'] = get_text(article.a['href'])\n",
        "      data.append(item)\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "cellView": "form",
        "id": "wkS9V4vJaqyh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Select days to pull news {run: \"auto\"}\n",
        "\n",
        "period = 'yesterday' #@param ['today', 'yesterday', 'more']\n",
        "\n",
        "def get_date(period):\n",
        "  if period == 'today':\n",
        "    return Date.today\n",
        "  elif period == 'yesterday':\n",
        "    return Date.yesterday\n",
        "  else:\n",
        "    return Date.more"
      ],
      "metadata": {
        "cellView": "form",
        "id": "pm1nGAJz_V1o"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Scraper Results\n",
        "date = get_date(period)\n",
        "data = scrape(date)\n",
        "print('total articles:', len(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "E8w37i1MHeq6",
        "outputId": "58d51764-20f7-41b9-9457-3ef8e073fad1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#### input ###\n",
            "date:  yesterday\n",
            "#### === ### \n",
            "\n",
            "total articles: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Summarize Articles"
      ],
      "metadata": {
        "id": "hM8jWTneZSKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Functions to summarize articles\n",
        "from IPython.display import Markdown\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import (\n",
        "    HumanMessage\n",
        ")\n",
        "\n",
        "def get_template(title, text):\n",
        "\n",
        "  # prepare template for prompt\n",
        "  template = \"\"\"You are an advanced ai assistant that summarizes online articles.\n",
        "\n",
        "  Here's the article you need to summarize:\n",
        "  ==========================\n",
        "  Title: {article_title}\n",
        "\n",
        "  Text: {article_text}\n",
        "  ==========================\n",
        "\n",
        "  Write a summary of the previous article in 100 words or less.\n",
        "  \"\"\"\n",
        "\n",
        "  prompt = template.format(article_title=title, article_text=text)\n",
        "\n",
        "  messages = [HumanMessage(content=prompt)]\n",
        "  return messages\n",
        "\n",
        "def get_summary(messages):\n",
        "\n",
        "  # instantiate model\n",
        "  chat = ChatOpenAI(temperature=0)\n",
        "\n",
        "  # generate summary\n",
        "  summary = chat(messages)\n",
        "  return summary.content\n",
        "\n",
        "def get_output(article):\n",
        "  title = article['title']\n",
        "  url = article['url']\n",
        "  date = article['time']\n",
        "  text = article['text']\n",
        "\n",
        "  messages = get_template(title, text)\n",
        "  summary = get_summary(messages)\n",
        "  output = f\"**{title}**<br>{summary} [View Full]({url})<br><br>\"\n",
        "  return output\n",
        "\n",
        "def summarize_articles(data):\n",
        "  markdown_list = []\n",
        "  for article in data:\n",
        "    t.sleep(30) # can only process 3 requests per minute on free account\n",
        "    output = get_output(article)\n",
        "    markdown_list.append(output)\n",
        "\n",
        "  markdown_string = ''.join(markdown_list)\n",
        "  return markdown_string\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "tzVSe7YTfm50"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Article Summaries\n",
        "summaries = summarize_articles(data)\n",
        "Markdown(summaries)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "cellView": "form",
        "id": "it9v9H95_e8b",
        "outputId": "35415b0d-3d44-49e4-adc7-b2c4be3aacfa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Perception Point launches AI model to combat generative AI-based BEC attacks**<br>Perception Point, an internet security platform, has launched a new AI-powered detection model to combat business email compromise (BEC) attacks facilitated by generative AI technologies. The model utilizes large language models (LLMs) and deep learning architecture to identify patterns in LLM-generated text, enabling the detection and prevention of sophisticated and personalized email threats. Perception Point's solution aims to address the limitations of conventional security vendors and offers a proactive approach by quarantining malicious emails before they reach the user's inbox. The model also incorporates a managed incident response service and exhibits exceptional speed in processing incoming emails. [View Full](https://venturebeat.com/ai/perception-point-launches-ai-model-to-combat-generative-ai-based-bec-attacks/)<br><br>**Capital One’s new chief scientist says ‘responsible, thoughtful’ generative AI is key**<br>Prem Natarajan, Capital One's new chief scientist and head of enterprise AI, believes that responsible and thoughtful implementation of generative AI is key for organizations. He sees a substantial opportunity for enterprises in the field of generative AI, particularly for those that have already committed to a technology transformation. Natarajan emphasizes the importance of operating generative AI in a responsible and inclusive manner, with diverse perspectives and considerations for different outcomes. Capital One is currently in a learning and experimenting phase with generative AI and large language models, with customer service being an early application contender. Natarajan's top priority is to build a world-class AI organization at Capital One. [View Full](https://venturebeat.com/ai/capital-ones-new-chief-scientist-says-responsible-thoughtful-generative-ai-is-key/)<br><br>**AI Foundation launches AI.XYZ to give people their own AI assistants**<br>AI Foundation has launched AI.XYZ, a platform that allows users to create their own AI assistants. The platform aims to promote a healthier work-life balance by offloading daily tasks to AI assistants. Unlike generic AI assistants from companies like Amazon and Google, AI.XYZ allows users to design unique AI assistants that know their values and goals, providing personalized help. The platform is available in public beta and offers both free and premium subscription options. AI Foundation believes that personal AI assistants can improve efficiency and productivity while protecting user data and privacy. [View Full](https://venturebeat.com/ai/ai-foundation-launches-ai-xyz-to-give-people-their-own-ai-assistants/)<br><br>**Inside the race to build an ‘operating system’ for generative AI**<br>Generative AI, which can auto-generate text, images, and code, is transforming the business world and could add $4.4 trillion to the global economy. However, enterprises face challenges in adopting this technology and need to develop an infrastructure to support the complex interactions between generative AI applications and other assets. This infrastructure can be likened to an operating system for generative AI, providing coordination, management, and monitoring capabilities. Intuit has developed its own platform, GenOS, encompassing data, development, runtime, and user experience layers. Other companies are also leveraging foundational large language models and open frameworks to enhance generative AI applications. [View Full](https://venturebeat.com/ai/inside-the-race-to-build-an-operating-system-for-generative-ai/)<br><br>"
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}